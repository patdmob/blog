{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://patdmob.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://patdmob.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Taking a .bat to scripts",
            "content": "Let’s suppose that we need to periodically run the same scripts (written in R or Python perhaps), and furthermore we’re using Windows. One of many possible solutions to this problem is to use a .bat file and then use a task scheduler to periodically run those scripts. . But why use a .bat file? If you are automating scripts, then just run the script! In Windows, a .bat file has the advantage of being flexibly executed. I can double click on it, use the cmd prompt, or I can throw it into a task scheduler and it will run. This flexibility is especially useful if you inconsistently execute the script or have not-so-tech-savvy end users. . But with this flexibility does come a challenge. How do .bat files pass absolute/relative paths to internal script calls? To solve this problem, I developed a quick test case to experiment. I wrote my test case in R but could have just as easily written it in Python. . Test case . My project directory contains the .bat file and separate folders for data and the R script. . The directory looks like this: . . In the R script, I reference a file in the data folder. . test_data &lt;- readRDS(&quot;./data/test_data.rds&quot;) print(getwd()) print(test_data) fileConn &lt;- file(&quot;result.txt&quot;) writeLines(getwd(), fileConn) close(fileConn) . This code will use a relative path to retrieve data from a separate folder and expects the root path “./” to be the project directory. . I’m not an expert at writing .bat files so I wrote a couple different scenarios to see what would happen. Eventually, I came up with the following code with comments. To the batch file (.bat) experts out there, please let me know if there is a better way. . @echo off REM This is a test to determine the working path REM when running RScript in BAT REM %CD% gives the path the script was called from REM %~dp0 will give the path of the script itself echo Called path: echo %CD% echo. echo Script path: echo %~dp0 echo. pause echo Works only if you run it from the .bat&#39;s directory: Rscript &quot;%~dp0 R bat_test.R&quot; echo. echo Works even if you run it from another directory: cd %~dp0 Rscript &quot;R bat_test.R&quot; echo. echo Press enter to close . . . pause &gt;nul exit . Here were my results: . . As you can see, I called the .bat file from my user profile directory. The first attempt fails but the second is a success. By using this second method, a user can flexibly execute the .bat file by double clicking, navigating from the cmd prompt, or using the task scheduler. .",
            "url": "https://patdmob.github.io/blog/blog/bat%20files/automation/windows/2018/12/15/Taking-a-bat-to-scripts.html",
            "relUrl": "/blog/bat%20files/automation/windows/2018/12/15/Taking-a-bat-to-scripts.html",
            "date": " • Dec 15, 2018"
        }
        
    
  
    
        ,"post3": {
            "title": "Missing Data Modeled",
            "content": "Outline . Introduction Example data Understanding the problem &amp; defining success Investigating missingness Methods to deal with missing data Missing data packages in R Conclusion Resources . Introduction . Missing data analysis is often overlooked in the data modeling process, yet it is essential for developing high quality models. Before cleaning, nearly every dataset contains missing data. As we prepare the dataset for modeling, we make various assumptions that impact how the production model will interact in the real-world. . Unfortunately, we can’t leave these decisions to algorithms. Most learners simply drop any records with missing data. And models that “support” missing data often only perform basic mean/mode imputation. These common but naive approaches to missingness can erode the data leaving it underpowered and/or biased–unable to answer intended questions. Fortunately, missing data analysis has provided us with a framework to overcome these challenges. . In this notebook, I provide an overview to missing data analysis. After reading this, you should have a solid understanding of the problem, considerations, and techniques relevant for missing data analysis. . Example data . Admittedly, the iris dataset is overused. But the data isn’t the point. It’s just a vehicle to get where we’re going. In case you haven’t interacted with the Iris dataset before: . Iris Dataset . There are three types of iris flowers, each with measurements for sepal length, sepal width, petal length, and petal width. . Setosa | Versicolour | Virginica | . The dataset contains 50 observations for each flower. . Understanding the problem &amp; defining success . Depending on your experience, you may already understand why missing data is a problem. However, let me formally define the problem and state a few goals which define success. . Loss of power . Statistical power refers to the amount of data required to reliably make a statistical claim. Simply said, missing data results in less usable data. Occasionally we have data to spare, but even small amounts of missing data can drastically reduce the size of usable data. In many fields, data collection is extremely costly and sometimes cannot be replicated. . If we randomly drop 6% of values, then a sample of the Iris dataset might look like this: . Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 NA 0.2 setosa 3 NA 3.2 1.3 0.2 &lt;NA&gt; 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa . Most models require complete data (no missing values) from which to learn. After removing rows with missing data, we only have 113 out of 150 complete rows. Therefore, even small amounts of missing data (6%) can result in large data loss (24.7%) from a modeling perspective. Generally, a good solution to missing data will maximize available data. . Bias . The second way missing data impacts a dataset is through bias. Consider the following chart. In this case, random elements were dropped from the data if petal length was less than 3.0. Perhaps the data collector had an unconscious bias against short petal iris flowers. . . At first glance, the available case distribution looks similar to the real data. But a common mistake in exploratory data analysis is to consider each variable individually and not compare this to what the model actually uses. If there is a pattern to the missingness, complete-case (only using complete rows) modeling will result in a biased model. At this point we need to ask ourselves why the data is missing. There can be multiple reasons which may require different strategies to address. . If we can successfully rule out any patterns to the missingness, then we can assume it is Missing Completely at Random (MCAR). The following chart shows data that is MCAR. . . Notice, even though the sample size decreases, the general distribution remains the same. If the data is MCAR, then bias is not a concern; however data is rarely MCAR. Regardless, a good solution for missing data will seek to make bias as small as possible. . Estimating uncertainty . Any method we use will change the shape of the data. Ideally, this altered shape should resemble the real data as closely as possible. But exactly how close is it? Much of statistics is primarily concerned about two things: estimating the magnitude of a statistic (mean, median, variance, etc.) and the probability/likelihood of occurrence. If we replace missing values with an estimate, how do we account for the variability in that estimate? Said differently, how confident are we that our estimates are accurate? . For this reason, advanced techniques like Multiple Imputations using Chained Equations (MICE) give a distribution of potential values. This provides an excellent way to correct estimates of uncertainty. However, it also makes modeling more complicated and is not appropriate for all applications. Even so, we should strive for accurate estimates of uncertainty (standard errors, confidence intervals, p-values, etc.). . Goals for Missing Data Analysis . To summarize, our goals1 are to: . Maximize the use of available information. | Minimize bias. | Yield good estimates of uncertainty. | These goals define success for our missing data problem. Of course, we must also balance these goals against any technical constraints of our project. For instance, streaming analytics will need computationally efficient methods which might not ideally solve the missing data but still provide a good enough proximity for the application. If this happens, it’s important to document these model limitations. . Investigating missingness . It’s important to understand why the data is missing. This could mean one or even multiple reasons. This will help us to choose an appropriate method and avoid biasing our dataset. . Consider how the data was collected . By understanding more about the data collection process, you’re able to discover potential reasons why data might be missing. . For instance, survey data commonly has missing data. Questions might be confusing or entice people to lie. A good solution for this is to interview a subset of respondents and understand their thought process. Perhaps this subset just didn’t know how to interpret the question. . Depending on the environment, there might be regular events which impact the data. Monthly power generator tests may briefly shut down computers collecting data. By talking with building management, you can get a schedule of events which may impact your data. . Regardless of the cause, understanding how the data was collected, its consistency, environment, etc. all help you to understand potential sources bias and missing data. . Visualizing the problem . It is common in Exploratory Data Analysis (EDA) to only visualize what is there, forgetting about what is not. Actually, much of missing data analysis is part of EDA. But how do you visualize what is not there? You look at the pattern! . Here I’ve used a packaged called VIM to visualize the missingness pattern: . #install.packages(&quot;VIM&quot;) require(VIM) aggr(iris_mis, col=c(&#39;darkred&#39;,&#39;slategrey&#39;),numbers=TRUE,sortVars=TRUE, labels=names(iris_mis2),cex.axis=.8,gap=3,ylab=c(&quot;Proportion of Missing Data&quot;,&quot;Pattern&quot;)) . . On the left, we have a bar chart showing the proportion of missing data for each variable. And on the right, we have can see the pattern of missingness for each combination of variables. For instance, 75.3% of the data is complete with no missing values. . When visualizing missing data, think about why it might be missing missing and how you plan on using the data in a model. Is a variable with high missingness necessary for the model? Will dropping observations with high missingness induce bias or critically impact power? What is the most/least common missingness pattern? Are there any missingness dependencies between variables (e.g. are two variables are always missing together)? . You can also look at any correlations between missing and present data. If we looked at a data set of heights and weights, perhaps taller individuals were more likely to have missing weight. If so, visualizing the histogram of height by missing weight frequency may reveal an interesting pattern. . Three types of missing data . While researching the data collection process and performing EDA, it helps to understand the three types of missing data. Each type has different implications. To illustrate, imagine that you’re a field investigator collecting household surveys to understand the labor market. . MCAR - Missing Completely At Random . You have just finished collecting surveys. On your way back to the office, a stack of surveys take flight on a gust of wind. As you scramble to catch them, some of the responses are obscured. . This is a case of Missing Completely At Random (MCAR). We know this because an unrelated outside event resulted in missing data. In other words, the cause of missingness is unrelated to the data. The wind doesn’t care which answers are obscured. It was a completely random accident. . If your data is MCAR, great! It’s the easiest of all missingness to handle. MCAR is un-biased missing data. Simple statistic imputation (mean, median, mode, etc.) is a perfectly legitimate method when your data is MCAR. If you have enough data, deleting rows with missingness (complete-case analysis) is also an option. Unfortunately, MCAR is the least common form of missing data. . MAR - Missing At Random . After entering the data and exploratory data analysis, you realize that an occupational subgroup has a high rate of missingness concerning their income (e.g. perhaps attorneys prefer not to disclose their income). While not ideal, this missingness is manageable since you are able to use other variables to tease out their likely income. In other words, the missingness is biased in some way explainable by the data. . This type of missingness is considered to be Missing At Random (MAR). Ironically, this is not the best name since it is really conditionally missing at random. But it’s historical so it stuck. . MNAR - Missing Not At Random . Lastly, suppose larger households omit the number of people living in the household. In this case, the reason for missingness depends on the missing values themselves and not on other variables for which we have information. Another case of MNAR would be if an unmeasured 3rd party is trying to influence the data. . This kind of missingness is considered Missing Not At Random (MNAR). MNAR is bias unexplained by current data. Unfortunately this kind of missingness is difficult to test for or solve. Sometimes the best way to overcome MNAR is by collecting additional information. . Difference between MAR and MNAR . One way to think about the difference between MAR and MNAR missingness is based on available information. Let’s say that we have a dataset with only one variable: Income. If income is missing for given observations, we have no other information from which to make an educated guess. This is MNAR. However, if we collect Occupation, Employed, Education, Age, Experience, etc. we might be able to make a much better guess at income. Now the missing data is MAR. The key difference is whether the bias can be explained by the current data. . Methods to deal with missing data . Consider . Three things to consider when choosing a method for handling missing data: . What is the type and cause of missingness? MCAR, MAR, or MNAR | Likely cause(s) | . | What is the shape of the data? Ordinal, nominal, continuous, discrete, time series, panel etc. | What does the distribution look like? | . | What are my constraints? Sample size (too large, too small) | Streaming or batch | Training time | . | . Each method makes different assumptions or is optimized for a particular type of data. Choose the method that fits your data type and problem best. You will likely need to learn a few different methods to handle various types of data. More complicated algorithms like Multiple Imputation using Chained Equations (MICE) or Maximum Likelihood can be complicated to set up and may take too much computation for a given application. . Methods . I’ve listed methods below in order of least to most complicated. For each variable with missingness, consider the methods at the top first. However, if you are conserned about power and bias, then you’ll need to adopt more complicated methods. Finally, if you have many variables with missingness, you may need to use a specialized algorithm which performs multiple imputation. . Note: Here I make the distinction between replacement, interpolation, and imputation, however they are all forms of imputation (i.e replacing a missing value with an estimated value). . Deletion List-wise (complete-case analysis) | Pair-wise (available-case analysis) | Observations or variables with too little information to be useful | . | Replacement Static value: mean, median, mode, constant, zeros, “missing” for categorical variables | Dynamic value: logical rules, LVCF, hot-deck, cold-deck, random | . | Interpolation Appropriate for data following a predictable pattern (1, 2, ?, 4, 5…) | Common for time-series or spatial data | . | Missingness Indicator Indicator variable to denote a replaced/interpolated/imputed missing value. This assumes there is a unobserved reason/pattern for missingness, and if not can induce bias | . | Imputation Single imputation uses other features to predict/approximate the correct value of one variable. In reality, this can be any common model used by predicting the missing values (e.g. regression, knn, etc.). | Multiple imputation imputes multiple variables at the same time. The rational being if multiple variables have biased missingness, then imputing one variable on others would result in biased imputation. These are usually specialized missing data models which iterate over each variable with missingness until convergence (e.g. MICE, Maximum Likelihood, missForest, etc.). | . | Combination | . Occationally, it makes sense to use create a missingness indicator for select variables. Let’s suppose that variable x’s missingness likely represents a group uncaptured by other variables. Then we should create a missingness indicator for variable x and impute missing values for x. . A dataset will probably require multiple methods. It is common to drop a variable with lots of missingness, then interpolate a date field, before performing multiple imputation on the rest. . Keep in Mind . All models are wrong, but some are useful . — famed statistician George Box . Your solution to missing data is just a model. It’s wrong, but it can be useful. Don’t take it too seriously, but know that it is important. . Missing data packages in R . This is by no means an exhaustive list, but these packages are fairly popular. . Imputation Hmisc - General package with functions for single and multiple imputation | missForest - Muliple Imputation based on Random Forest algorithm | MICE - Muliple Imputation using Chained Equations | Amelia - Imputation for time series data | . | Tools and visualization mitools - Tools for multiple imputation of missing data | VIM - Visualization and Imputation of Missing values | . | . In the following examples, we’ll use the biased Iris dataset (random elements were dropped if petal length was less than 3.0). . Example in Hmisc . #install.packages(&quot;Hmisc&quot;) require(Hmisc) . impute() function replaces the missing value with user defined statistical method (default=median | mean | max etc.) | . iris_mis$imputed.Petal.Length &lt;- with(iris_mis, impute(Petal.Length, mean)) iris_mis$imputed.Petal.Width &lt;- with(iris_mis, impute(Petal.Width, mean)) . However, as we can see below, using mean imputation increases the bias making it difficult to identify Setosa, the species with the smallest petal length. . . For this reason, you should use more advanced methods when dealing with biased missing data. Even unbiased data will benefit depending on your choice of analytic model (decision trees are probably more affected by mean imputation than linear regression). . aregImpute() function creates multiple imputations using additive regression, bootstrapping, and predictive mean matching. . imputed_aregImpute &lt;- aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width + Species, data = iris_mis, n.impute = 5) . 5 separate imputations to yield good estimates of uncertainty. The literature suggests 20 or more imputations. . But for now, we want to pool those imputations to graph the results. . imputed &lt;- as.data.frame(impute.transcan(imputed_aregImpute, imputation = 1, data = iris_mis, list.out = TRUE, pr=FALSE, check=FALSE)) . Here, muliple imputation does a much better job at matching the shape of the original data. . . Example in MICE . MICE stands for Multivariate Imputation using Chained Equations . #install.packages(&quot;mice&quot;) require(mice) imputed_mice &lt;- mice(data = iris_mis[1:5], m = 5, method = &quot;pmm&quot;, maxit=50, seed=500) . It is one of the more complicated methods, however it does a great job of imputing missing variables. . . Example in missForest . #install.packages(&quot;missForest&quot;) require(missForest) . missForest is a relatively newer imputation algorithm and uses an iterative random forest approach to missing data. It accomplishes this by estimating the accuracy of these predictions and adjusts the model. You can also run it in parallel when installing the package doParallel. . Imputing with missForest: . #install.packages(&quot;doParallel&quot;) require(doParallel) registerDoParallel() #registering the processor getDoParWorkers() #number of processors running #vignette(&quot;gettingstartedParallel&quot;) #for more information imputed_forest &lt;- missForest(iris_mis[1:5], parallelize = &quot;forest&quot;) imputed_forest$OOBerror #calling Out Of Bag error iris_mis.forest &lt;- imputed_forest$ximp . As you can see, it also does quite well. . . Conclusion . While often overlooked, missing data analysis plays an important role in the modeling process. Common but naive approaches often leave datasets underpowered or biased which could impact real-world model performance. . Missing data analysis is conscerned with making the best use of availible information while minimizing bias and maintaining accurate estimates of uncertainty. To do this, it is important to understand the type of and causes for missingness. We also need to balance the goals of success with the technical constraints of the problem. Afterward, a reasonable approach to handle missing data often becomes clear. . There are a variety of methods developed to overcome the problem of missing data. This article highlights a few of them. As this is a growing field, new methods constantly appear. . Resources . This notebook: . https://github.com/patdmob/Missing-Data . Articles: . http://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/ . http://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/ . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/ . Chapters: . http://www.statisticalhorizons.com/wp-content/uploads/2012/01/Milsap-Allison.pdf . Footnotes . 1 These goals are adopted from Paul Allison’s chapter on missing data referenced in the resources section. ↩ .",
            "url": "https://patdmob.github.io/blog/tutorial/missing%20data/r%20programming/2018/07/15/Missing-Data-Modeled.html",
            "relUrl": "/tutorial/missing%20data/r%20programming/2018/07/15/Missing-Data-Modeled.html",
            "date": " • Jul 15, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Life has it’s ups and downs. But I’ve always liked to learn. It’s fun to discover the world and how it works. It’s always enjoyable to Netflix and chill but so much more satifying to Make something. Part of my life is maintaining a balance between these two. . I took a two-year hiatus from writing posts. But I’ve found my spark again so you should see much more to come. Topics might be all over the place; I took this space too serously last time. So now I’ll write whatever takes my fancy: perhaps topics like electronics, Raspberry Pi, data science, or economics. . I program in mostly Python these days but I’m not committing to anything. You’ll see older posts in R. And as I learn and work more with microprocessors and microcontrollers you might see something else. . Thanks and I hope you enjoy. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://patdmob.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://patdmob.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}